{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nANlK2huQA-X",
        "outputId": "8012f1cc-6bd2-4775-b466-4ebfa989513c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "BASE_DIR = \"/content/drive/MyDrive/bert\"\n",
        "print(os.listdir(BASE_DIR))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BSfVpLHpVqaS",
        "outputId": "def79e89-58c1-4f59-cc65-a90d2bfc6190"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['bert_embeddings_uncased.npy', 'labels.npy', 'metadata.pkl', 'roberta_embeddings.npy', 'albert_embeddings.npy']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "import os\n",
        "\n",
        "BASE_DIR = \"/content/drive/MyDrive/bert\"\n",
        "\n",
        "X = np.load(os.path.join(BASE_DIR, \"bert_embeddings_uncased.npy\"))\n",
        "y = np.load(os.path.join(BASE_DIR, \"labels.npy\"))\n",
        "\n",
        "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "clf = LogisticRegression(max_iter=1000)\n",
        "clf.fit(X_train, y_train)\n",
        "\n",
        "y_pred = clf.predict(X_val)\n",
        "print(\"Validation Accuracy:\", accuracy_score(y_val, y_pred))\n",
        "print(classification_report(y_val, y_pred))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Oyi-oqZEVyp4",
        "outputId": "b429f056-82d7-49d4-fb68-1bb68e4c63f2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Accuracy: 0.8174\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.82      0.82      0.82      5055\n",
            "           1       0.82      0.81      0.81      4945\n",
            "\n",
            "    accuracy                           0.82     10000\n",
            "   macro avg       0.82      0.82      0.82     10000\n",
            "weighted avg       0.82      0.82      0.82     10000\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "import os\n",
        "\n",
        "BASE_DIR = \"/content/drive/MyDrive/bert\"\n",
        "\n",
        "X = np.load(os.path.join(BASE_DIR, \"bert_embeddings_uncased.npy\"))\n",
        "y = np.load(os.path.join(BASE_DIR, \"labels.npy\"))\n",
        "\n",
        "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "clf = SVC(kernel='linear')\n",
        "clf.fit(X_train, y_train)\n",
        "\n",
        "y_pred = clf.predict(X_val)\n",
        "print(\"Validation Accuracy:\", accuracy_score(y_val, y_pred))\n",
        "print(classification_report(y_val, y_pred))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wnmEIOmMWFVR",
        "outputId": "d7a1e79a-7f1d-4baf-eb2a-22257f1ebc4d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Accuracy: 0.8182\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.82      0.82      0.82      5055\n",
            "           1       0.82      0.81      0.82      4945\n",
            "\n",
            "    accuracy                           0.82     10000\n",
            "   macro avg       0.82      0.82      0.82     10000\n",
            "weighted avg       0.82      0.82      0.82     10000\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "import os\n",
        "\n",
        "BASE_DIR = \"/content/drive/MyDrive/bert\"\n",
        "\n",
        "X = np.load(os.path.join(BASE_DIR, \"bert_embeddings_uncased.npy\"))\n",
        "y = np.load(os.path.join(BASE_DIR, \"labels.npy\"))\n",
        "\n",
        "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "clf = RandomForestClassifier(n_estimators=100)\n",
        "clf.fit(X_train, y_train)\n",
        "\n",
        "y_pred = clf.predict(X_val)\n",
        "print(\"Validation Accuracy:\", accuracy_score(y_val, y_pred))\n",
        "print(classification_report(y_val, y_pred))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a0KLGkkLcw9u",
        "outputId": "3e2db92b-404d-43aa-d25d-839ea71053b8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Accuracy: 0.7767\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.79      0.77      0.78      5055\n",
            "           1       0.77      0.79      0.78      4945\n",
            "\n",
            "    accuracy                           0.78     10000\n",
            "   macro avg       0.78      0.78      0.78     10000\n",
            "weighted avg       0.78      0.78      0.78     10000\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "import os\n",
        "\n",
        "BASE_DIR = \"/content/drive/MyDrive/bert\"\n",
        "\n",
        "X = np.load(os.path.join(BASE_DIR, \"bert_embeddings_uncased.npy\"))\n",
        "y = np.load(os.path.join(BASE_DIR, \"labels.npy\"))\n",
        "\n",
        "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "clf = GradientBoostingClassifier()\n",
        "clf.fit(X_train, y_train)\n",
        "\n",
        "y_pred = clf.predict(X_val)\n",
        "print(\"Validation Accuracy:\", accuracy_score(y_val, y_pred))\n",
        "print(classification_report(y_val, y_pred))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fejO61Wedg6A",
        "outputId": "e94a6875-8aad-4103-9fb0-6c33b403218c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Accuracy: 0.7855\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.79      0.79      0.79      5055\n",
            "           1       0.78      0.79      0.78      4945\n",
            "\n",
            "    accuracy                           0.79     10000\n",
            "   macro avg       0.79      0.79      0.79     10000\n",
            "weighted avg       0.79      0.79      0.79     10000\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "import os\n",
        "\n",
        "BASE_DIR = \"/content/drive/MyDrive/bert\"\n",
        "\n",
        "X = np.load(os.path.join(BASE_DIR, \"bert_embeddings_uncased.npy\"))\n",
        "y = np.load(os.path.join(BASE_DIR, \"labels.npy\"))\n",
        "\n",
        "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "clf = MLPClassifier(hidden_layer_sizes=(128,), max_iter=300)\n",
        "clf.fit(X_train, y_train)\n",
        "\n",
        "y_pred = clf.predict(X_val)\n",
        "print(\"Validation Accuracy:\", accuracy_score(y_val, y_pred))\n",
        "print(classification_report(y_val, y_pred))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gHwJkmYJ8LYb",
        "outputId": "d99d2750-1e2e-46b4-8b77-c3fd5ae0da82"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Accuracy: 0.7976\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.81      0.79      0.80      5055\n",
            "           1       0.79      0.81      0.80      4945\n",
            "\n",
            "    accuracy                           0.80     10000\n",
            "   macro avg       0.80      0.80      0.80     10000\n",
            "weighted avg       0.80      0.80      0.80     10000\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "from sklearn.linear_model import LogisticRegression, SGDClassifier\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "import itertools\n",
        "import os\n",
        "\n",
        "# --- Load BERT embeddings ---\n",
        "BASE_DIR = \"/content/drive/MyDrive/bert\"\n",
        "X = np.load(os.path.join(BASE_DIR, \"bert_embeddings_uncased.npy\"))\n",
        "y = np.load(os.path.join(BASE_DIR, \"labels.npy\"))\n",
        "\n",
        "# --- Split data ---\n",
        "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# --- Define models and their parameter grids ---\n",
        "param_grids = {\n",
        "    \"Logistic Regression\": {\n",
        "        \"C\": [0.01, 0.1, 1, 10],\n",
        "        \"solver\": [\"lbfgs\", \"saga\"],\n",
        "        \"max_iter\": [200, 300]\n",
        "    },\n",
        "    \"SVM\": {\n",
        "        \"C\": [0.1, 1, 10],\n",
        "        \"kernel\": [\"linear\", \"rbf\"]\n",
        "    },\n",
        "    \"MLP\": {\n",
        "        \"hidden_layer_sizes\": [(64,), (128,), (64,64)],\n",
        "        \"activation\": [\"relu\", \"tanh\"],\n",
        "        \"max_iter\": [200, 300]\n",
        "    },\n",
        "    \"Naive Bayes\": {\n",
        "        \"alpha\": [0.5, 1.0, 1.5]\n",
        "    },\n",
        "    \"SGD Classifier\": {\n",
        "        \"loss\": [\"hinge\", \"log\"],\n",
        "        \"alpha\": [0.0001, 0.001],\n",
        "        \"max_iter\": [1000, 2000]\n",
        "    }\n",
        "}\n",
        "\n",
        "# --- Function to iterate over parameter combinations ---\n",
        "def param_combinations(grid):\n",
        "    keys = grid.keys()\n",
        "    values = grid.values()\n",
        "    for instance in itertools.product(*values):\n",
        "        yield dict(zip(keys, instance))\n",
        "\n",
        "# --- Train and evaluate ---\n",
        "results = []\n",
        "\n",
        "for model_name, grid in param_grids.items():\n",
        "    print(f\"=== {model_name} ===\")\n",
        "    for params in param_combinations(grid):\n",
        "        if model_name == \"Logistic Regression\":\n",
        "            model = LogisticRegression(**params)\n",
        "        elif model_name == \"SVM\":\n",
        "            model = SVC(**params)\n",
        "        elif model_name == \"MLP\":\n",
        "            model = MLPClassifier(**params)\n",
        "        elif model_name == \"Naive Bayes\":\n",
        "            model = MultinomialNB(**params)\n",
        "        elif model_name == \"SGD Classifier\":\n",
        "            model = SGDClassifier(**params)\n",
        "\n",
        "        model.fit(X_train, y_train)\n",
        "        y_pred = model.predict(X_val)\n",
        "        acc = accuracy_score(y_val, y_pred)\n",
        "        results.append({\n",
        "            \"Model\": model_name,\n",
        "            \"Params\": params,\n",
        "            \"Accuracy\": round(acc, 4)\n",
        "        })\n",
        "\n",
        "# --- Sort by Accuracy ---\n",
        "results_sorted = sorted(results, key=lambda x: x[\"Accuracy\"], reverse=True)\n",
        "\n",
        "# --- Print top 10 results ---\n",
        "for r in results_sorted[:10]:\n",
        "    print(r)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f0ByS0gHChjZ",
        "outputId": "dd53054f-c441-4618-beed-cf0265cb0fa8"
      },
      "execution_count": null,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "=== Logistic Regression ===\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== SVM ===\n"
          ]
        }
      ]
    }
  ]
}